{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaptiveMD\n",
    "\n",
    "## Example 2 - Running of Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stop RP from printing logs until severe\n",
    "# verbose = os.environ.get('RADICAL_PILOT_VERBOSE', 'REPORT')\n",
    "os.environ['RADICAL_PILOT_VERBOSE'] = 'ERROR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jan-hendrikprinz/anaconda/lib/python2.7/site-packages/radical/utils/atfork/stdlib_fixer.py:58: UserWarning: logging module already imported before fixup.\n",
      "  warnings.warn('logging module already imported before fixup.')\n"
     ]
    }
   ],
   "source": [
    "from adaptivemd import (\n",
    "    Project,\n",
    "    Event, FunctionalEvent\n",
    ")\n",
    "\n",
    "from adaptivemd.engine.openmm import OpenMMEngine\n",
    "from adaptivemd.analysis.pyemma import PyEMMAAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's open our `test` project by its name. If you completed the previous example this should all work out of the box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "project = Project('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open all connections to the `MongoDB` and `Session` so we can get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see where we are. These numbers will depend on whether you run this notebook for the first time or just continue again. Unless you delete your project it will accumulate models and files over time, as is our ultimate goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<StoredBundle with 18 file(s) @ 0x120eb17d0>\n",
      "<StoredBundle with 2 file(s) @ 0x120eb1790>\n",
      "<StoredBundle with 0 file(s) @ 0x120eb1750>\n"
     ]
    }
   ],
   "source": [
    "print project.files\n",
    "print project.generators\n",
    "print project.models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now restore our old ways to generate tasks by loading the previously used generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engine = project.generators['openmm']\n",
    "modeller = project.generators['pyemma']\n",
    "pdb_file = project.files['initial_pdb']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we really start simulations. The general way to do so is to create a simulation task and then submit it to a cluster to be executed. A `Task` object is a general description of what should be done and boils down to staging some files to your working directory, executing a bash script and finally moving files back from your working directory to a shared storage. RP takes care of most of this very elegantly and hence a `Task` is designed somewhat to cover the capabilities but in a somehow simpler and more pythonic way.\n",
    "\n",
    "For example there is a RPC Python Call Task that allows you to execute a function remotely and pull back the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional Events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to first look into a way to run python code asynchroneously in the project. For this, write a function that should be executed. Start with opening a scheduler or using an existing one (in the latter case you need to make sure that when it is executed - which can take a while - the scheduler still exists).\n",
    "\n",
    "If the function should pause, write `yield {condition_to_continue}`. This will interrupt your script until the function you return will return `True` when called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def strategy():\n",
    "    # create a new scheduler\n",
    "    local_scheduler = project.get_scheduler(cores=2)\n",
    "    # run 10 trajs of length 100 in parallel\n",
    "    tasks = local_scheduler.submit(project.new_ml_trajectory(\n",
    "        length=100, number=10))\n",
    "    # continue (all tasks need to be done)\n",
    "    yield tasks.is_done()\n",
    "    # close scheduler when job is done\n",
    "    local_scheduler.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "turn a generator of your function use add `strategy()` and not `strategy` to the `FunctionalEvent`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ev = FunctionalEvent(strategy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and execute the event inside your project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<adaptivemd.event.FunctionalEvent at 0x11ffbf1d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.add_event(ev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after some time you will have 10 more trajectories. Just like that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of files 1\n"
     ]
    }
   ],
   "source": [
    "print '# of files', len(project.trajectories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To actually run simulations you need to have a scheduler (maybe a better name?). This instance can execute tasks or more precise you can use it to submit tasks which will be converted to ComputeUnitDescriptions and executed on the cluster previously chosen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scheduler = project.get_scheduler(cores=2)  # get the default scheduler using 2 cores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are good to go and can run a first simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works by creating a Trajectory object with a filename, a length and an initial frame. Then the engine will take this information and create a real trajectory with exactly this name, this initil frame and the given length.\n",
    "\n",
    "Since this is such a common task you can also submit just a `Trajectory` without the need tp convert it to a `Task` first (which the engine can also do)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out project can create new names automatically and so we want 4 new trajectories of length 100 and starting at the existing pdb_file we use to initialize the engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trajs = project.new_trajectory(pdb_file, 100, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's submit and see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<adaptivemd.task.Task at 0x121c3b990>,\n",
       " <adaptivemd.task.Task at 0x1210f0110>,\n",
       " <adaptivemd.task.Task at 0x121c3bdd0>,\n",
       " <adaptivemd.task.Task at 0x11fa68090>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler.submit(trajs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the trajectories exist these objects will be saved to the database. It might be a little confusing to have objects before they exist, but this way you can actually work with these trajectories like referencing even before they exist.\n",
    "\n",
    "This would allow to write now a function that triggers when the trajectory comes into existance. But we are not doing this right now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait is dangerous since it is blocking and you cannot do anything until all tasks are finished. Normally you do not need it. Especially in interactive sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scheduler.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at all the files our project now contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of files 22\n"
     ]
    }
   ],
   "source": [
    "print '# of files', len(project.files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! That was easy (I hope you agree). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to run a simple analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = modeller.execute(list(project.trajectories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<adaptivemd.task.PythonTask at 0x121c7cc90>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scheduler.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the model we generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<StoredBundle with 1 file(s) @ 0x120eb1750>\n"
     ]
    }
   ],
   "source": [
    "print project.models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And pick some information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.80434783  0.03429576  0.05531053  0.10604588  0.        ]\n",
      " [ 0.01791559  0.81122449  0.08288145  0.03996614  0.04801233]\n",
      " [ 0.04185879  0.12007304  0.83806817  0.          0.        ]\n",
      " [ 0.09418292  0.06794849  0.          0.7974359   0.04043269]\n",
      " [ 0.          0.12800292  0.          0.06340333  0.80859375]]\n"
     ]
    }
   ],
   "source": [
    "print project.models.last.data['msm']['P']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next example will demonstrate on how to write a full adaptive loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A new concept. Tasks are great and do work for us. But so far we needed to submit tasks ourselves. In adaptive simulations we want this to happen automagically. To help with some of this events exist. This are basically a task_generator coupled with conditions on when to be executed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a little task generator (in essence a function that returns tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def task_generator():\n",
    "    return [\n",
    "        engine.task_run_trajectory(traj) for traj in\n",
    "        project.new_ml_trajectory(100, 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<adaptivemd.task.Task at 0x121367a50>,\n",
       " <adaptivemd.task.Task at 0x121435350>,\n",
       " <adaptivemd.task.Task at 0x121435e50>,\n",
       " <adaptivemd.task.Task at 0x121460190>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create an event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ev = Event().on(project.on_ntraj(range(20,22,2))).do(task_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.on` specifies when something should be executed. In our case when the project has a number of 20 trajectories. This is not yet the case so this event will not do anything unless we simulation more trajectories.\n",
    "\n",
    "`.do` specifies the function to be called.\n",
    "\n",
    "The concept is borrowed from event based languages like often used in JavaScript. \n",
    "\n",
    "You can build quite complex execution patterns with this. An event for example also knows when it is finished and this can be used as another trigger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hello():\n",
    "    print 'DONE!!!'\n",
    "    return []  # todo: allow for None here\n",
    "\n",
    "finished = Event().on(ev.on_done).do(hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<adaptivemd.event.Event at 0x12156d050>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler.add_event(ev)\n",
    "scheduler.add_event(finished)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All events and tasks run parallel or at least get submitted and queue for execution in parallel. RP takes care of the actual execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of files 34\n"
     ]
    }
   ],
   "source": [
    "print '# of files', len(project.files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for now lets run more trajectories and schedule computation of models in regular intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<adaptivemd.event.Event at 0x121528ad0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev1 = Event().on(project.on_ntraj(range(30, 70, 4))).do(task_generator)\n",
    "ev2 = Event().on(project.on_ntraj(38)).do(lambda: modeller.execute(list(project.trajectories))).repeat().until(ev1.on_done)\n",
    "scheduler.add_event(ev1)\n",
    "scheduler.add_event(ev2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(project.trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(project.models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.repeat` means to redo the same task when the last is finished (it will just append an infinite list of conditions to keep on running).\n",
    "\n",
    "`.until` specifies a termination condition. The event will not be executed once this condition is met. Makes most sense if you use `.repeat` or if the trigger condition and stopping should be independent. You might say, run 100 times unless you have a good enough model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<StoredBundle with 70 file(s) @ 0x12056f3d0>\n"
     ]
    }
   ],
   "source": [
    "print project.files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategies (aka **the brain**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The brain is just a collection of events. This makes it reuseable and easy to extend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "project.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
