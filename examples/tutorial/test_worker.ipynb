{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaptiveMD\n",
    "\n",
    "## Example 1 - Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os, time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to stop RP from reporting all sorts of stuff for this example so we set a specific environment variable to tell RP to do so. If you want to see what RP reports change it to `REPORT`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# verbose = os.environ.get('RADICAL_PILOT_VERBOSE', 'REPORT')\n",
    "os.environ['RADICAL_PILOT_VERBOSE'] = 'ERROR'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will import the appropriate parts from AdaptiveMD as we go along so it is clear what it needed at what stage. Usually you will have the block of imports at the beginning of your script or notebook as suggested in PEP8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from adaptivemd import Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from adaptivemd import OpenMMEngine\n",
    "from adaptivemd import PyEMMAAnalysis\n",
    "\n",
    "from adaptivemd import File, Directory, WorkerScheduler\n",
    "\n",
    "from adaptivemd import DT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's open a project with a UNIQUE name. This will be the name used in the DB so make sure it is new and not too short. Opening a project will always create a non-existing project and reopen an exising one. You cannot chose between opening types as you would with a file. This is a precaution to not accidentally delete your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Project.delete('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "project = Project('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a handle for our project. First thing is to set it up to work on a resource."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Set the resource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is a resource? A `Resource` specifies a shared filesystem with one or more clusteres attached to it. This can be your local machine or just a regular cluster or even a group of cluster that can access the same FS (like Titan, Eos and Rhea do).\n",
    "\n",
    "Once you have chosen your place to store your results this way it is set for the project and can (at least should) not be altered since all file references are made to match this resource. Currently you can use the Fu Berlin Allegro Cluster or run locally. There are two specific local adaptations that include already the path to your conda installation. This simplifies the use of `openmm` or `pyemma`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us pick a local resource on a laptop for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from adaptivemd import LocalCluster, AllegroCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resource_id = 'local.jhp'\n",
    "\n",
    "resource = LocalCluster()\n",
    "resource.wrapper.append('source activate xyz')\n",
    "\n",
    "if resource_id == 'local.jhp':\n",
    "    project.initialize(resource)\n",
    "elif resource_id == 'local.sheep':\n",
    "    project.initialize(LocalCluster())\n",
    "elif resource_id == 'fub.allegro':\n",
    "    project.initialize(AllegroCluster())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TaskGenerators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TaskGenerators are instances whose purpose is to create tasks to be executed. This is similar to the\n",
    "way Kernels work. A TaskGenerator will generate `Task` objects for you which will be translated into a `ComputeUnitDescription` and executed. In simple terms:\n",
    "\n",
    "**The task generator creates the bash scripts for you that run a simulation or run pyemma.**\n",
    "\n",
    "A task generator will be initialized with all parameters needed to make it work and it will now what needs to be staged to be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A task generator that will create jobs to run simulations. Currently it uses a little python script that will excute OpenMM. It requires conda to be added to the PATH variable or at least openmm to be installed on the cluster. If you setup your resource correctly then this should all happen automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define a `File` object. These are used to represent files anywhere, on the cluster or your local application. `File` like any complex object in adaptivemd can have a `.name` attribute that makes them easier to find later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pdb_file = File('file://../files/alanine/alanine.pdb').named('initial_pdb').load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we used a special prefix that can point to specific locations. \n",
    "\n",
    "- `file://` points to files on your local machine. \n",
    "- `unit://` specifies files on the current working directory of the executing node. Usually these are temprary files for a single execution.\n",
    "- `shared://` specifies the root shared FS directory (e.g. `NO_BACKUP/` on Allegro) Use this to import and export files that are already on the cluster.\n",
    "- `staging://` a special scheduler specific directory where files are moved after they are completed on a node and should be used for later. Use this to relate to files that should be stored or reused. After you one excution is done you usually move all important files to this place.\n",
    "- `sandbox://` this should not concern you and is a special RP folder where all pilot/session folders are located."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's do an example for an OpenMM engine. This is simply a small python script that makes OpenMM look like a executable. It run a simulation by providing an initial frame, OpenMM specific system.xml and integrator.xml files and some additional parameters like the platform name, how often to store simulation frames, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engine = OpenMMEngine(\n",
    "    pdb_file=pdb_file,\n",
    "    system_file=File('file://../files/alanine/system.xml').load(),\n",
    "    integrator_file=File('file://../files/alanine/integrator.xml').load(),\n",
    "    args='-r --report-interval 1 -p CPU --store-interval 1'\n",
    ").named('openmm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explain this we have now an OpenMMEngine which uses the previously made pdb `File` object and uses the location defined in there. The same some Files for the OpenMM XML files and some args to store each frame (to keep it fast) and run using the `CPU` kernel.\n",
    "\n",
    "Last we name the engine `openmm` to find it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'openmm'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The modeller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The instance to compute an MSM model of existing trajectories that you pass it. It is initialized with a `.pdb` file that is used to create features between the $c_\\alpha$ atoms. This implementaton requires a PDB but in general this is not necessay. It is specific to my PyEMMAAnalysis show case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modeller = PyEMMAAnalysis(\n",
    "    pdb_file=pdb_file\n",
    ").named('pyemma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we name it `pyemma` for later reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add generators to project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to add these to the project for later usage. We pick the `.generators` store and just add it. Consider a store to work like a `set()` in python. It contains objects only once and is not ordered. Therefore we need a name to find the objects later. Of course you can always iterate over all objects, but the order is not given.\n",
    "\n",
    "To be precise there is an order in the time of creation of the object, but it is only accurate to seconds and it really is the time it was created and not stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added file OpenMMEngine\n",
      "Added file PyEMMAAnalysis\n"
     ]
    }
   ],
   "source": [
    "project.generators.add(engine)\n",
    "project.generators.add(modeller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed to booting\n",
      "Changed to running\n"
     ]
    }
   ],
   "source": [
    "sc = WorkerScheduler(project.resource)\n",
    "sc.enter(project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = engine.task_run_trajectory(project.new_trajectory(pdb_file, 100, restart=True)). extend(50).extend(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['export PATH=aa:$PATH',\n",
       " 'export PATH=hello_again:$PATH',\n",
       " 'export PATH=what:$PATH',\n",
       " 'source activate xyz',\n",
       " 'ln -s ../staging_area/alanine.pdb initial.pdb',\n",
       " 'ln -s ../staging_area/system.xml system.xml',\n",
       " 'ln -s ../staging_area/integrator.xml integrator.xml',\n",
       " 'ln -s ../staging_area/openmmrun.py openmmrun.py',\n",
       " 'ln -s ../../projects/test/trajs/00000000.dcd source.dcd',\n",
       " 'ln -s ../../projects/test/trajs/00000000.dcd.restart in.restart',\n",
       " 'python openmmrun.py -r --report-interval 1 -p CPU --store-interval 1 --restart in.restart  -t initial.pdb --length 100 extension.dcd',\n",
       " 'mdconvert -o output.dcd -t initial.pdb source.dcd extension.dcd',\n",
       " 'echo \"DONE!\"',\n",
       " 'mv extension.dcd.restart ../../projects/test/trajs/00000000.dcd.restart',\n",
       " 'mv output.dcd ../../projects/test/trajs/00000000.dcd']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.task_to_script(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000000.dcd 250 11:19:22\n"
     ]
    }
   ],
   "source": [
    "sc.advance()\n",
    "for f in project.trajectories:\n",
    "    print f.basename, f.length, DT(f.created).time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:18:29 [worker:3] \n",
      "11:19:13 [worker:3] Warning: 'topology' data from input file(s) will be discarded. output format only supports fields: 'xyz', 'cell_lengths', 'cell_angles'\n",
      "\n",
      "11:19:22 [worker:3] Warning: 'topology' data from input file(s) will be discarded. output format only supports fields: 'xyz', 'cell_lengths', 'cell_angles'\n",
      "\n",
      "11:21:24 [worker:3] Warning: 'topology' data from input file(s) will be discarded. output format only supports fields: 'xyz', 'cell_lengths', 'cell_angles'\n",
      "\n",
      "11:21:16 [worker:3] \n"
     ]
    }
   ],
   "source": [
    "for t in project.tasks:\n",
    "    print t.stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<adaptivemd.logentry.LogEntry object at 0x10caa5c50>\n",
      "<adaptivemd.logentry.LogEntry object at 0x10caa5d90>\n",
      "<adaptivemd.logentry.LogEntry object at 0x10caa5c90>\n",
      "<adaptivemd.logentry.LogEntry object at 0x10caa5e10>\n",
      "<adaptivemd.logentry.LogEntry object at 0x10caa5d10>\n",
      "<adaptivemd.logentry.LogEntry object at 0x10caa5d90>\n"
     ]
    }
   ],
   "source": [
    "for l in project.logs:\n",
    "    print repr(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<StoredBundle with 2 file(s) @ 0x10c979750>\n"
     ]
    }
   ],
   "source": [
    "print project.generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t1 = engine.task_run_trajectory(project.new_trajectory(pdb_file, 100, restart=True))\n",
    "t2 = t1.extend(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added file TrajectoryGenerationTask\n"
     ]
    }
   ],
   "source": [
    "project.tasks.add(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Link('staging:///alanine.pdb' > 'initial.pdb'),\n",
       " Link('staging:///system.xml' > 'system.xml'),\n",
       " Link('staging:///integrator.xml' > 'integrator.xml'),\n",
       " Link('staging:///openmmrun.py' > 'openmmrun.py'),\n",
       " Link('sandbox:///projects/test/trajs/00000000.dcd' > 'source.dcd'),\n",
       " Link('sandbox:///projects/test/trajs/00000000.dcd.restart' > 'in.restart')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.append('source activate enb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['python openmmrun.py -r --report-interval 1 -p CPU --store-interval 1 --restart in.restart  -t initial.pdb --length 100 extension.dcd',\n",
       " 'mdconvert -o output.dcd -t initial.pdb source.dcd extension.dcd']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t._user_pre_exec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<adaptivemd.task.Task at 0x10c979a90>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.wrapper.pre_exec('source activate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sandbox 00000000.dcd 100 1488816219.52 1488816205 True 0x60e23714028611e78222000000000068L\n",
      "sandbox 00000000.dcd 200 None 1488816205 False 0x60e23714028611e7822200000000008eL\n"
     ]
    }
   ],
   "source": [
    "for f in project.trajectories:\n",
    "    print f.drive, f.basename, len(f), f.created, f.__time__, f.exists, hex(f.__uuid__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file /Users/jan-hendrikprinz/Studium/git/adaptive-sampling/package/adaptivemd/scripts/_run_.py None 1488816183 False 0x60e23714028611e78222000000000002L\n",
      "file /Users/jan-hendrikprinz/Studium/git/adaptive-sampling/package/adaptivemd/engine/openmm/openmmrun.py None 1488816184 False 0x60e23714028611e78222000000000004L\n",
      "file /Users/jan-hendrikprinz/Studium/git/adaptive-sampling/package/examples/files/alanine/alanine.pdb None 1488816200 False 0x60e23714028611e7822200000000003aL\n",
      "file /Users/jan-hendrikprinz/Studium/git/adaptive-sampling/package/examples/files/alanine/system.xml None 1488816200 False 0x60e23714028611e7822200000000003cL\n",
      "file /Users/jan-hendrikprinz/Studium/git/adaptive-sampling/package/examples/files/alanine/integrator.xml None 1488816200 False 0x60e23714028611e7822200000000003eL\n",
      "sandbox /projects/test/trajs/00000000.dcd 1488816219.52 1488816205 True 0x60e23714028611e78222000000000068L\n",
      "unit 00000000.restart 1488816219.52 1488816213 True 0x60e23714028611e7822200000000006aL\n",
      "sandbox /projects/test/trajs/00000000.dcd None 1488816205 False 0x60e23714028611e7822200000000008eL\n"
     ]
    }
   ],
   "source": [
    "for f in project.files:\n",
    "    print f.drive, f.path, f.created, f.__time__, f.exists, hex(f.__uuid__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "w = project.workers.last\n",
    "print w.state\n",
    "print w.command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed Stevie.fritz.box\n",
      "success Stevie.fritz.box\n"
     ]
    }
   ],
   "source": [
    "for t in project.tasks:\n",
    "    print t.state, t.worker.hostname if t.worker else 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<adaptivemd.engine.engine.TrajectoryGenerationTask at 0x10cec5610>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc.advance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t1 = engine.task_run_trajectory(project.new_trajectory(pdb_file, 100))\n",
    "t2 = t1.extend(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added file <adaptivemd.engine.engine.TrajectoryGenerationTask object at 0x10cd93a10>\n"
     ]
    }
   ],
   "source": [
    "project.tasks.add(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from adaptivemd.engine import Trajectory\n",
    "# t3 = engine.task_run_trajectory(Trajectory('staging:///trajs/0.dcd', pdb_file, 100)).extend(100)\n",
    "# t3.dependencies = []\n",
    "\n",
    "# def get_created_files(t, s):\n",
    "#     if t.is_done():\n",
    "#         print 'done', s\n",
    "#         return s - set(t.added_files)\n",
    "#     else:\n",
    "#         adds = set(t.added_files)\n",
    "#         rems = set(s.required[0] for s in t._pre_stage)\n",
    "#         print '+', adds\n",
    "#         print '-', rems\n",
    "#         q = set(s) - adds | rems \n",
    "        \n",
    "#         if t.dependencies is not None:\n",
    "#             for d in t.dependencies:                \n",
    "#                 q = get_created_files(d, q)\n",
    "\n",
    "#         return q\n",
    "    \n",
    "# get_created_files(t3, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stevie.fritz.box releaseunfinished\n"
     ]
    }
   ],
   "source": [
    "for w in project.workers:\n",
    "    print w.hostname, w.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "releaseunfinished\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "w = project.workers.last\n",
    "print w.state\n",
    "print w.command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w.command = 'shutdown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success Stevie.fritz.box\n",
      "success Stevie.fritz.box\n",
      "queued Stevie.fritz.box\n",
      "success Stevie.fritz.box\n",
      "created None\n",
      "created None\n",
      "created None\n",
      "created None\n",
      "created None\n",
      "created None\n"
     ]
    }
   ],
   "source": [
    "for t in project.tasks:\n",
    "    print t.state, t.worker.hostname if t.worker else 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sandbox 00000000.dcd 100 1488811288.83 1488811284 True 0xf6345b8a027a11e7a1bb00000000007cL\n",
      "sandbox 00000001.dcd 100 1488811302.4 1488811290 True 0xf6345b8a027a11e7a1bb0000000000a0L\n",
      "sandbox 00000001.dcd 200 1488811310.45 1488811290 True 0xf6345b8a027a11e7a1bb0000000000c2L\n",
      "sandbox 00000002.dcd 100 1488811602.49 1488811552 True 0xf6345b8a027a11e7a1bb000000000140L\n",
      "sandbox 00000002.dcd 200 1488811610.53 1488811552 True 0xf6345b8a027a11e7a1bb000000000162L\n",
      "sandbox 00000003.dcd 100 None 1488811553 False 0xf6345b8a027a11e7a1bb000000000192L\n",
      "sandbox 00000003.dcd 200 None 1488811553 False 0xf6345b8a027a11e7a1bb0000000001b4L\n"
     ]
    }
   ],
   "source": [
    "for f in project.trajectories:\n",
    "    print f.drive, f.basename, len(f), f.created, f.__time__, f.exists, hex(f.__uuid__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Frame(00000000.dcd[0])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.trajectories.one[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = engine.task_run_trajectory(project.new_trajectory(project.trajectories.one[0], 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added file <adaptivemd.engine.engine.TrajectoryGenerationTask object at 0x10c8e9490>\n"
     ]
    }
   ],
   "source": [
    "project.tasks.add(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<StoredBundle with 21 file(s) @ 0x10ccb4e50>\n",
      "<StoredBundle with 15 file(s) @ 0x10ccb4e90>\n"
     ]
    }
   ],
   "source": [
    "print project.files\n",
    "print project.tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = modeller.execute(list(project.trajectories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "project.tasks.add(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from uuid import UUID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "project.storage.tasks._document.find_one({'_dict': {'generator' : { '_dict': }}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<adaptivemd.task.Task at 0x10594d550>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genlist = ['openmm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ln -s ../staging_area/alanine.pdb initial.pdb', 'ln -s ../staging_area/system.xml system.xml', 'ln -s ../staging_area/integrator.xml integrator.xml', 'ln -s ../staging_area/openmmrun.py openmmrun.py', 'ln -s ../staging_area/trajs/00000000.dcd input.dcd', 'hostname', 'mdconvert -o input.pdb -i 0 -t initial.pdb input.dcd', 'python \"openmmrun.py\" \"-r\" \"--report-interval\" \"1\" \"-p\" \"CPU\" \"--store-interval\" \"1\" \"-t\" \"input.pdb\" \"--length\" \"100\" \"output.dcd\"', 'mv output.dcd ../staging_area/trajs/00000004.dcd']\n",
      "task succeeded. State: success\n",
      "Added file sandbox:///workers/staging_area/trajs/00000004.dcd\n"
     ]
    }
   ],
   "source": [
    "scheduler = sc\n",
    "prefetch = 1\n",
    "\n",
    "while True:\n",
    "    scheduler.advance()\n",
    "    if scheduler.is_idle:\n",
    "        for _ in range(prefetch):\n",
    "            tasklist = scheduler(project.storage.tasks.consume_one())\n",
    "\n",
    "        if len(tasklist) == 0:\n",
    "            break\n",
    "\n",
    "    time.sleep(2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, that you cannot add the same engine twice. But if you create a new engine it will be considered different and hence you can store it again. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create one intial trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we are ready to run a first trajectory that we will store as a point of reference in the project. Also it is nice to see how it works in general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Open a scheduler \n",
    "\n",
    "a job on the cluster to execute tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the `.get_scheduler` function delegates to the resource and uses the `get_scheduler` functions from there. This is merely a convenience since a `Scheduler` has the responsibility to open queues on the resource for you. \n",
    "\n",
    "You have the same options as the queue has in the resource. This is often the number of cores and walltime, but can be additional ones, too. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's open the default queue and use a single core for it since we only want to run one simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scheduler = project.get_scheduler(cores=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create the parameter for the engine to run the simulation. Since it seemed appropriate we use a `Trajectory` object (a special `File` with initial frame and length) as the input. You could of course pass these things separately, but this way, we can actualy reference the no yet existing trajectory and do stuff with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Trajectory should have a unique name and so there is a project function to get you one. It uses numbers and makes sure that this number has not been used yet in the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory('alanine.pdb' >> 00000000.dcd[0..100])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectory = project.new_trajectory(engine['pdb_file'], 100)\n",
    "trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This says, initial is `alanine.pdb` run for 100 frames and is named `xxxxxxxx.dcd`.\n",
    "\n",
    "Now, we want that this trajectory actually exists so we have to make it (on the cluster which is waiting for things to do). So we need a `Task` object to run a simulation. Since `Task` objects are very flexible there are helper functions to get them to do, what you want, like the ones we already created just before. Let's use the openmm engine to create an openmm task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "task = engine.task_run_trajectory(trajectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it, just that a trajectory description and turn it into a task that contains the shell commands and needed files, etc. \n",
    "\n",
    "Last step is to really run the task. You can just use a scheduler as a function or call the `.submit()` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<adaptivemd.task.Task at 0x1214190d0>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to wait. To see, if we are done, you can check the scheduler if it is still running tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* unit.000000  state Failed (None), out/err:  / \n",
      "task did not complete\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler.is_idle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<StoredBundle with 0 file(s) @ 0x11f942810>\n"
     ]
    }
   ],
   "source": [
    "print scheduler.generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or you wait until it becomes idle using `.wait()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scheduler.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all went as expected we will now have our first trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<StoredBundle with 0 file(s) @ 0x11f942850>\n",
      "<ViewBundle with 0 file(s) @ 0x11f942890>\n"
     ]
    }
   ],
   "source": [
    "print project.files\n",
    "print project.trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent, so cleanup and close our queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scheduler.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and close the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "project.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The final project.close() will also shut down all open schedulers for you, so the exit command would not be necessary here. It is relevant if you want to exit the queue as soon as possible to save walltime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have finally created an AdaptiveMD project and run your first trajectory. Since the project exists now, it is\n",
    "much easier to run more trajectories now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}