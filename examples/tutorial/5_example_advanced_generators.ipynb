{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaptiveMD\n",
    "\n",
    "## Example 5 - Custom `Generator` objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from adaptivemd import (\n",
    "    Project, Task, File, PythonTask\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's open our `test` project by its name. If you completed the first examples this should all work out of the box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "project = Project('tutorial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open all connections to the `MongoDB` and `Session` so we can get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see again where we are. These numbers will depend on whether you run this notebook for the first time or just continue again. Unless you delete your project it will accumulate models and files over time, as is our ultimate goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<StoredBundle for with 123 file(s) @ 0x111718a10>\n",
      "<StoredBundle for with 2 file(s) @ 0x1117189d0>\n",
      "<StoredBundle for with 18 file(s) @ 0x111718990>\n"
     ]
    }
   ],
   "source": [
    "print project.files\n",
    "print project.generators\n",
    "print project.models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now restore our old ways to generate tasks by loading the previously used generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engine = project.generators['openmm']\n",
    "modeller = project.generators['pyemma']\n",
    "pdb_file = project.files['initial_pdb']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A word about this example. While a `Task` can be created and configured a new class in `adaptivemd` needs to be part of the project. So we will write discuss the essential parts of the existing code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A generator is in essence a factory to create `Task` objects with a single command. A generator can be initialized with certain files that the created tasks will always need, like an engine will need a topology for each task, etc. It also (as explained briefly before in Example 4) knows about certain callback behaviour of their tasks. Last, a generator allows you to assign a worker only to tasks that were created by a generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The execution structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the code of the PyEMMAAnalysis\n",
    "\n",
    "```py\n",
    "class PyEMMAAnalysis(Analysis):\n",
    "    def __init__(self, pdb_file):\n",
    "        super(PyEMMAAnalysis, self).__init__()\n",
    "\n",
    "        self['pdb_file'] = pdb_file\n",
    "        stage = pdb_file.transfer('staging:///')\n",
    "\n",
    "        self['pdb_file_stage'] = stage.target\n",
    "        self.initial_staging.append(stage)\n",
    "\n",
    "    @staticmethod\n",
    "    def then_func(project, task, model, inputs):\n",
    "        # add the input arguments for later reference\n",
    "        model.data['input']['trajectories'] = inputs['files']\n",
    "        model.data['input']['pdb'] = inputs['topfile']\n",
    "        project.models.add(model)\n",
    "\n",
    "    def task_run_msm_files(\n",
    "            self,\n",
    "            trajectories,\n",
    "            tica_lag=2,\n",
    "            tica_dim=2,\n",
    "            msm_states=5,\n",
    "            msm_lag=2,\n",
    "            stride=1):\n",
    "\n",
    "        t = PythonTask(self)\n",
    "\n",
    "        input_pdb = t.link(self['pdb_file_stage'], 'input.pdb')\n",
    "        t.call(\n",
    "            remote_analysis,\n",
    "            trajectories=list(trajectories),\n",
    "            topfile=input_pdb,\n",
    "            tica_lag=tica_lag,\n",
    "            tica_dim=tica_dim,\n",
    "            msm_states=msm_states,\n",
    "            msm_lag=msm_lag,\n",
    "            stride=stride\n",
    "        )\n",
    "\n",
    "        return t\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "def __init__(self, pdb_file):\n",
    "    # don't forget to call super\n",
    "    super(PyEMMAAnalysis, self).__init__()  \n",
    "\n",
    "    # a generator also acts like a dictionary for files\n",
    "    # this way you can later access certain files you might need\n",
    "    \n",
    "    # save the pdb_file under the same name\n",
    "    self['pdb_file'] = pdb_file  \n",
    "\n",
    "    # this creates a transfer action like it is used in tasks\n",
    "    # and moves the passed pdb_file (usually on the local machein)\n",
    "    # to the staging_area root directory\n",
    "    stage = pdb_file.transfer('staging:///')\n",
    "    \n",
    "    # and the new target file (which is also like the original) \n",
    "    # on the staging_area is saved unter `pdb_file_stage`\n",
    "    # so, we can access both files if we wanted to\n",
    "    # note that the original file most likely is in the DB\n",
    "    # so we could just skip the stage transfer completely\n",
    "    self['pdb_file_stage'] = stage.target\n",
    "    \n",
    "    # last we add this transfer to the initial_staging which\n",
    "    # is done only once per used generator\n",
    "    self.initial_staging.append(stage)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "# the kwargs is to keep the exmaple short, you should use explicit\n",
    "# parameters and add appropriate docs\n",
    "def task_run_msm_files(self, trajectories, **kwargs):\n",
    "    # create the task and set the generator to self, our new generator\n",
    "    t = PythonTask(self)\n",
    "\n",
    "    # we want to copy the staged file to the worker directory\n",
    "    # and name it `input.pdb`\n",
    "    input_pdb = t.link(self['pdb_file_stage'], 'input.pdb')\n",
    "    \n",
    "    # if you chose not to use the staging file and copy it directly you\n",
    "    # would use in analogy\n",
    "    # input_pdb = t.link(self['pdb_file'], 'input.pdb')\n",
    "\n",
    "    # finally we use `.call` and want to call the `remote_analysis` function\n",
    "    # which we imported earlier from somewhere\n",
    "    t.call(\n",
    "        remote_analysis,\n",
    "        trajectories=list(trajectories),\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    return t\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally a call_back function. The name `then_func` is the default function name to be called."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "# we use a static method, but you can of course write a normal method\n",
    "@staticmethod\n",
    "# the call_backs take these arguments in this order\n",
    "# the second parameter is actually a `Model` object in this case\n",
    "# which has a `.data` attribute\n",
    "def then_func(project, task, model, inputs):\n",
    "    # add the input arguments for later reference to the model\n",
    "    model.data['input']['trajectories'] = inputs['kwargs']['files']\n",
    "    model.data['input']['pdb'] = inputs['kwargs']['topfile']\n",
    "    # and save the model in the project\n",
    "    project.models.add(model)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A brief summary and things you need to set to make your generator work\n",
    "\n",
    "```py\n",
    "class MyGenerator(Analysis):\n",
    "    def __init__(self, {things your generator always needs}):\n",
    "        super(MyGenerator, self).__init__()\n",
    "        \n",
    "        # Add input files to self\n",
    "        self['file1'] = file1\n",
    "\n",
    "        # stage all files to the staging area of you want to keep these\n",
    "        # files on the HPC\n",
    "        for fn in ['file1', 'file2', ...]:\n",
    "            stage = self[fn].transfer('staging:///')\n",
    "            self[fn + '_stage'] = stage.target\n",
    "            self.initial_staging.append(stage)\n",
    "\n",
    "    @staticmethod\n",
    "    def then_func(project, task, outputs, inputs):\n",
    "        # do something with input and outputs\n",
    "        # store something in your project\n",
    "\n",
    "    def task_using_python_rpc(\n",
    "            self,\n",
    "            {arguments}):\n",
    "\n",
    "        t = PythonTask(self)\n",
    "\n",
    "        # set any task dependencies if you need\n",
    "        t.dependencies = []\n",
    "                \n",
    "        input1 = t.link(self['file1'], 'alternative_name1')\n",
    "        input2 = t.link(self['file2'], 'alternative_name2')\n",
    "        ...\n",
    "\n",
    "        # add whatever bash stuff you need BEFORE the function call\n",
    "        t.append('some bash command')\n",
    "        ...\n",
    "\n",
    "        # use input1, etc in your function call if you like. It will\n",
    "        # be converted to a regular file location you can use\n",
    "        t.call(\n",
    "            {my_remote_python_function},\n",
    "            files=list(files),\n",
    "        )\n",
    "\n",
    "        # add whatever bash stuff you need AFTER the function call\n",
    "        t.append('some bash command')\n",
    "        ...\n",
    "\n",
    "        return t\n",
    "\n",
    "    def task_using_bash_argument_call(\n",
    "            self,\n",
    "            {arguments}):\n",
    "\n",
    "        t = Task(self)\n",
    "\n",
    "        # set any task dependencies if you need\n",
    "        t.dependencies = []\n",
    "\n",
    "        input1 = t.link(self['file1'], 'alternative_name1')\n",
    "        input2 = t.link(self['file2'], 'alternative_name2')\n",
    "        ...\n",
    "        # add more staging\n",
    "        t.append({action})\n",
    "        ...\n",
    "\n",
    "        # add whatever bash stuff you want to do\n",
    "        t.append('some bash command')\n",
    "        ...\n",
    "\n",
    "        # add whatever staging stuff you need AFTER the function call\n",
    "        t.append({action})\n",
    "        ...\n",
    "        \n",
    "        return t\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplified code for the OpenMMEngine\n",
    "\n",
    "```py\n",
    "class OpenMMEngine(Engine):\n",
    "    trajectory_ext = 'dcd'\n",
    "\n",
    "    def __init__(self, system_file, integrator_file, pdb_file, args=None):\n",
    "        super(OpenMMEngine, self).__init__()\n",
    "\n",
    "        self['pdb_file'] = pdb_file\n",
    "        self['system_file'] = system_file\n",
    "        self['integrator_file'] = integrator_file\n",
    "        self['_executable_file'] = exec_file\n",
    "\n",
    "        for fn in self.files:\n",
    "            stage = self[fn].transfer(Location('staging:///'))\n",
    "            self[name + '_stage'] = stage.target\n",
    "            self.initial_staging.append(stage)\n",
    "\n",
    "        if args is None:\n",
    "            args = '-p CPU --store-interval 1'\n",
    "\n",
    "        self.args = args\n",
    "\n",
    "    # this one only works if you start from a file\n",
    "    def task_run_trajectory_from_file(self, target):\n",
    "        # we create a special Task, that has some additional functionality\n",
    "        t = TrajectoryGenerationTask(self, target)\n",
    "\n",
    "        # link all the files we require\n",
    "        initial_pdb = t.link(self['pdb_file_stage'], Location('initial.pdb'))\n",
    "        t.link(self['system_file_stage'])\n",
    "        t.link(self['integrator_file_stage'])\n",
    "        t.link(self['_executable_file_stage'])\n",
    "\n",
    "        # use the initial PDB to be used\n",
    "        input_pdb = t.get(target.frame, 'coordinates.pdb')\n",
    "\n",
    "        # this represents our output trajectory\n",
    "        output = Trajectory('traj/', target.frame, length=target.length, engine=self)\n",
    "\n",
    "        # create the directory so openmmrun can write to it\n",
    "        t.touch(output)\n",
    "\n",
    "        # build the actual bash command\n",
    "        cmd = 'python openmmrun.py {args} -t {pdb} --length {length} {output}'.format(\n",
    "            pdb=input_pdb,\n",
    "            length=target.length,\n",
    "            output=output,\n",
    "            args=self.args,\n",
    "        )\n",
    "        t.append(cmd)\n",
    "        \n",
    "        # copy the resulting trajectory directory back to the staging area\n",
    "        t.put(output, target)\n",
    "\n",
    "        return t\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "project.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
